{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231d4d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_seq: (142857, 7, 80)\n",
      "y_seq: (142857,)\n",
      "Train: (91428, 7, 80) Val: (22857, 7, 80) Test: (28572, 7, 80)\n",
      "Resampled train: (114172, 7, 80) [91338 22834]\n",
      "Class weights: None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 7, 128)            107008    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 128)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156481 (611.25 KB)\n",
      "Trainable params: 156481 (611.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "\n",
      "Epoch 1: val_pr_auc improved from -inf to 0.02562, saving model to artifacts/best_lstm.weights.h5\n",
      "892/892 - 28s - loss: 0.1118 - roc_auc: 0.9876 - pr_auc: 0.9578 - precision: 0.9281 - recall: 0.8435 - val_loss: 0.0138 - val_roc_auc: 0.6272 - val_pr_auc: 0.0256 - val_precision: 0.0556 - val_recall: 0.0870 - lr: 0.0010 - 28s/epoch - 32ms/step\n",
      "Epoch 2/30\n",
      "\n",
      "Epoch 2: val_pr_auc improved from 0.02562 to 0.02729, saving model to artifacts/best_lstm.weights.h5\n",
      "892/892 - 23s - loss: 0.0069 - roc_auc: 0.9998 - pr_auc: 0.9990 - precision: 0.9925 - recall: 0.9976 - val_loss: 0.0145 - val_roc_auc: 0.6483 - val_pr_auc: 0.0273 - val_precision: 0.0882 - val_recall: 0.1304 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 3/30\n",
      "\n",
      "Epoch 3: val_pr_auc improved from 0.02729 to 0.06326, saving model to artifacts/best_lstm.weights.h5\n",
      "892/892 - 23s - loss: 0.0029 - roc_auc: 1.0000 - pr_auc: 0.9996 - precision: 0.9972 - recall: 0.9989 - val_loss: 0.0122 - val_roc_auc: 0.5426 - val_pr_auc: 0.0633 - val_precision: 0.2500 - val_recall: 0.0870 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 4/30\n",
      "\n",
      "Epoch 4: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 23s - loss: 0.0023 - roc_auc: 1.0000 - pr_auc: 0.9999 - precision: 0.9975 - recall: 0.9988 - val_loss: 0.0140 - val_roc_auc: 0.5861 - val_pr_auc: 0.0275 - val_precision: 0.0909 - val_recall: 0.0435 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 5/30\n",
      "\n",
      "Epoch 5: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 24s - loss: 0.0016 - roc_auc: 1.0000 - pr_auc: 0.9999 - precision: 0.9983 - recall: 0.9993 - val_loss: 0.0145 - val_roc_auc: 0.5429 - val_pr_auc: 0.0215 - val_precision: 0.1667 - val_recall: 0.0435 - lr: 0.0010 - 24s/epoch - 26ms/step\n",
      "Epoch 6/30\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 6: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 23s - loss: 0.0013 - roc_auc: 1.0000 - pr_auc: 0.9998 - precision: 0.9989 - recall: 0.9993 - val_loss: 0.0138 - val_roc_auc: 0.5643 - val_pr_auc: 0.0327 - val_precision: 0.1538 - val_recall: 0.0870 - lr: 0.0010 - 23s/epoch - 26ms/step\n",
      "Epoch 7/30\n",
      "\n",
      "Epoch 7: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 24s - loss: 2.3180e-04 - roc_auc: 1.0000 - pr_auc: 1.0000 - precision: 0.9998 - recall: 1.0000 - val_loss: 0.0147 - val_roc_auc: 0.5431 - val_pr_auc: 0.0207 - val_precision: 0.1429 - val_recall: 0.0435 - lr: 5.0000e-04 - 24s/epoch - 27ms/step\n",
      "Epoch 8/30\n",
      "\n",
      "Epoch 8: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 24s - loss: 1.5469e-05 - roc_auc: 1.0000 - pr_auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0154 - val_roc_auc: 0.5432 - val_pr_auc: 0.0171 - val_precision: 0.1111 - val_recall: 0.0435 - lr: 5.0000e-04 - 24s/epoch - 26ms/step\n",
      "Epoch 9/30\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 9: val_pr_auc did not improve from 0.06326\n",
      "892/892 - 24s - loss: 1.4613e-05 - roc_auc: 1.0000 - pr_auc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0158 - val_roc_auc: 0.5432 - val_pr_auc: 0.0284 - val_precision: 0.1429 - val_recall: 0.0435 - lr: 5.0000e-04 - 24s/epoch - 27ms/step\n",
      "23/23 [==============================] - 2s 43ms/step\n",
      "28/28 [==============================] - 1s 44ms/step\n",
      "\n",
      "VAL ROC AUC: 0.7596 | PR AUC: 0.0760\n",
      "\n",
      "TEST ROC AUC: 0.8053 | PR AUC: 0.0570\n",
      "\n",
      "Chosen thresholds:\n",
      "- Best-F1 on VAL: 0.908635 (F1=0.1481, P=0.5000, R=0.0870)\n",
      "- Cost-min on VAL: 0.908302 (min cost=212.00, FN cost=10.0, FP cost=1.0)\n",
      "- Target recall≥0.70: 0.908635\n",
      "\n",
      "=== TEST Best-F1 (threshold=0.908635) ===\n",
      "Confusion Matrix:\n",
      "[[28540     4]\n",
      " [   27     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.9999    0.9995     28544\n",
      "           1     0.2000    0.0357    0.0606        28\n",
      "\n",
      "    accuracy                         0.9989     28572\n",
      "   macro avg     0.5995    0.5178    0.5300     28572\n",
      "weighted avg     0.9983    0.9989    0.9985     28572\n",
      "\n",
      "\n",
      "=== TEST Cost-Optimal (threshold=0.908302) ===\n",
      "Confusion Matrix:\n",
      "[[28540     4]\n",
      " [   27     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.9999    0.9995     28544\n",
      "           1     0.2000    0.0357    0.0606        28\n",
      "\n",
      "    accuracy                         0.9989     28572\n",
      "   macro avg     0.5995    0.5178    0.5300     28572\n",
      "weighted avg     0.9983    0.9989    0.9985     28572\n",
      "\n",
      "\n",
      "=== TEST Target-Recall (threshold=0.908635) ===\n",
      "Confusion Matrix:\n",
      "[[28540     4]\n",
      " [   27     1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9991    0.9999    0.9995     28544\n",
      "           1     0.2000    0.0357    0.0606        28\n",
      "\n",
      "    accuracy                         0.9989     28572\n",
      "   macro avg     0.5995    0.5178    0.5300     28572\n",
      "weighted avg     0.9983    0.9989    0.9985     28572\n",
      "\n",
      "\n",
      "Saved LSTM to fraud_lstm_model.keras\n",
      "Artifacts in: artifacts/ (threshold_sweep_val.csv, chosen_thresholds.json, best_lstm.keras)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------ Repro ------------------\n",
    "import random\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# ------------------ TF / Keras ------------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# ------------------ Sklearn / metrics ------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, roc_auc_score, average_precision_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# ------------------ Imbalance handling ------------------\n",
    "from imblearn.over_sampling import RandomOverSampler  # swap for SMOTE if desired\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# ------------------ Optional: XGBoost baseline ------------------\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAVE_XGB = True\n",
    "except Exception:\n",
    "    HAVE_XGB = False\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "DATA_PATH = \"transactions_processed.npz\"\n",
    "SEQUENCE_LENGTH = 7           # timesteps per sequence\n",
    "VAL_SIZE = 0.2                # validation split from train\n",
    "TEST_SIZE = 0.2               # test split from all data\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30                   # bump epochs; EarlyStopping will stop earlier\n",
    "USE_OVERSAMPLING = True       # True -> RandomOverSampler on train\n",
    "USE_CLASS_WEIGHTS = False     # avoid double counting with oversampling\n",
    "USE_FOCAL_LOSS = False        # optional focal loss instead of BCE\n",
    "\n",
    "# Cost matrix for cost-sensitive thresholding (tune to your business)\n",
    "COST_FN = 10.0   # cost of missing a fraud (false negative)\n",
    "COST_FP = 1.0    # cost of a false alarm (false positive)\n",
    "\n",
    "MODEL_OUT = \"fraud_lstm_model.keras\"\n",
    "ARTIFACTS_DIR = \"artifacts\"\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def make_sequences(X, y, seq_len):\n",
    "    \"\"\"Chunk flat events into non-overlapping sequences.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    usable = (n // seq_len) * seq_len\n",
    "    X = X[:usable]\n",
    "    y = y[:usable]\n",
    "    X_seq = X.reshape(-1, seq_len, X.shape[1])\n",
    "    # label the sequence by the LAST timestep's label (common for fraud next-event prediction)\n",
    "    y_seq = y.reshape(-1, seq_len)[:, -1]\n",
    "    return X_seq, y_seq\n",
    "\n",
    "def focal_loss(gamma=3.0, alpha=0.8):\n",
    "    def _loss(y_true, y_pred):\n",
    "        eps = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        w = tf.where(tf.equal(y_true, 1), alpha, 1 - alpha)\n",
    "        return -w * tf.pow(1 - pt, gamma) * tf.math.log(pt)\n",
    "    return _loss\n",
    "\n",
    "def sweep_thresholds(y_true, y_proba, betas=(0.5, 1, 2), resolution=500):\n",
    "    \"\"\"Return DataFrame with precision, recall, F1/Fβ across thresholds.\"\"\"\n",
    "    thresholds = np.linspace(1e-6, 0.999999, resolution)\n",
    "    rows = []\n",
    "    for t in thresholds:\n",
    "        yp = (y_proba >= t).astype(int)\n",
    "        p = precision_score(y_true, yp, zero_division=0)\n",
    "        r = recall_score(y_true, yp, zero_division=0)\n",
    "        f1 = (2*p*r/(p+r)) if (p+r)>0 else 0.0\n",
    "        row = {\"threshold\": t, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "        for b in betas:\n",
    "            if p==0 and r==0:\n",
    "                fbeta = 0.0\n",
    "            else:\n",
    "                fbeta = (1+b*b)*p*r / (b*b*p + r + 1e-12)\n",
    "            row[f\"f{b}\"] = fbeta\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "def cost_for_threshold(y_true, y_proba, thr, cost_fn=COST_FN, cost_fp=COST_FP):\n",
    "    yp = (y_proba >= thr).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, yp).ravel()\n",
    "    return cost_fn*fn + cost_fp*fp\n",
    "\n",
    "def pick_cost_min_threshold(y_true, y_proba, resolution=2000, cost_fn=COST_FN, cost_fp=COST_FP):\n",
    "    thresholds = np.linspace(1e-6, 0.999999, resolution)\n",
    "    costs = [cost_for_threshold(y_true, y_proba, t, cost_fn, cost_fp) for t in thresholds]\n",
    "    idx = int(np.argmin(costs))\n",
    "    return float(thresholds[idx]), float(costs[idx])\n",
    "\n",
    "def evaluate_at(y_true, y_proba, thr, title):\n",
    "    yp = (y_proba >= thr).astype(int)\n",
    "    print(f\"\\n=== {title} (threshold={thr:.6f}) ===\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, yp))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, yp, digits=4))\n",
    "    p = precision_score(y_true, yp, zero_division=0)\n",
    "    r = recall_score(y_true, yp, zero_division=0)\n",
    "    f1 = f1_score(y_true, yp, zero_division=0)\n",
    "    return {\"precision\": p, \"recall\": r, \"f1\": f1}\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load & sequence\n",
    "# =========================\n",
    "data = np.load(DATA_PATH)\n",
    "X_raw, y_raw = data[\"X\"], data[\"y\"].astype(int)\n",
    "num_features = X_raw.shape[1]\n",
    "X_seq, y_seq = make_sequences(X_raw, y_raw, SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"X_seq:\", X_seq.shape)   # (num_sequences, sequence_length, num_features)\n",
    "print(\"y_seq:\", y_seq.shape)   # (num_sequences,)\n",
    "\n",
    "# =========================\n",
    "# Train/Val/Test split\n",
    "# =========================\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_seq, y_seq, test_size=TEST_SIZE, stratify=y_seq, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE, stratify=y_train_full, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# =========================\n",
    "# Imbalance handling\n",
    "# =========================\n",
    "if USE_OVERSAMPLING:\n",
    "    # Flatten sequences to resample by sequence\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    # For extreme imbalance, you can choose a higher target minority ratio, e.g., 0.25\n",
    "    ros = SMOTE(random_state=SEED, sampling_strategy=0.5, k_neighbors=2)\n",
    "    # smote = SMOTE(random_state=SEED, sampling_strategy=0.25)  # alternative\n",
    "    X_res, y_res = ros.fit_resample(X_train_flat, y_train)\n",
    "    X_train_res = X_res.reshape(-1, SEQUENCE_LENGTH, num_features)\n",
    "    y_train_res = y_res\n",
    "    print(\"Resampled train:\", X_train_res.shape, np.bincount(y_train_res))\n",
    "else:\n",
    "    X_train_res, y_train_res = X_train, y_train\n",
    "\n",
    "# Optional class weights (usually use either oversampling OR weights, not both)\n",
    "if USE_CLASS_WEIGHTS:\n",
    "    n0 = np.sum(y_train_res == 0)\n",
    "    n1 = np.sum(y_train_res == 1)\n",
    "    # Balanced heuristic\n",
    "    w0 = (1.0 / n0) * (n0 + n1) / 2.0\n",
    "    w1 = (1.0 / n1) * (n0 + n1) / 2.0\n",
    "    class_weight = {0: w0, 1: w1}\n",
    "else:\n",
    "    class_weight = None\n",
    "print(\"Class weights:\", class_weight)\n",
    "\n",
    "# =========================\n",
    "# Build model\n",
    "# =========================\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(SEQUENCE_LENGTH, num_features), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.AUC(name=\"roc_auc\", curve=\"ROC\"),\n",
    "    tf.keras.metrics.AUC(name=\"pr_auc\", curve=\"PR\"),\n",
    "    tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "loss_fn = focal_loss() if USE_FOCAL_LOSS else \"binary_crossentropy\"\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=focal_loss(gamma=3.0, alpha=0.8),\n",
    "    metrics=metrics\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# =========================\n",
    "# Training callbacks\n",
    "# =========================\n",
    "ckpt_path = os.path.join(ARTIFACTS_DIR, \"best_lstm.weights.h5\")  # <- weights file\n",
    "cbs = [\n",
    "    EarlyStopping(monitor=\"val_pr_auc\", mode=\"max\", patience=6, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor=\"val_pr_auc\", mode=\"max\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(\n",
    "        ckpt_path,\n",
    "        monitor=\"val_pr_auc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,   # <- important\n",
    "        verbose=1\n",
    "    ),\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Train\n",
    "# =========================\n",
    "history = model.fit(\n",
    "    X_train_res, y_train_res,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=cbs,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Restore best weights\n",
    "model.load_weights(ckpt_path)\n",
    "\n",
    "# =========================\n",
    "# Evaluate (probabilities)\n",
    "# =========================\n",
    "y_val_probs = model.predict(X_val, batch_size=1024).ravel()\n",
    "y_test_probs = model.predict(X_test, batch_size=1024).ravel()\n",
    "\n",
    "def summarize_split(name, y_true, y_prob):\n",
    "    roc = roc_auc_score(y_true, y_prob)\n",
    "    pr  = average_precision_score(y_true, y_prob)\n",
    "    print(f\"\\n{name} ROC AUC: {roc:.4f} | PR AUC: {pr:.4f}\")\n",
    "    return roc, pr\n",
    "\n",
    "val_roc, val_pr = summarize_split(\"VAL\", y_val, y_val_probs)\n",
    "test_roc, test_pr = summarize_split(\"TEST\", y_test, y_test_probs)\n",
    "\n",
    "# =========================\n",
    "# Threshold selection\n",
    "# =========================\n",
    "# 1) Best-F1\n",
    "sweep = sweep_thresholds(y_val, y_val_probs, betas=(0.5, 1, 2), resolution=800)\n",
    "best_f1_row = sweep.iloc[sweep[\"f1\"].idxmax()].to_dict()\n",
    "best_f1_thr = float(best_f1_row[\"threshold\"])\n",
    "\n",
    "# 2) Cost-minimizing\n",
    "cost_thr, min_cost = pick_cost_min_threshold(y_val, y_val_probs, resolution=3000, cost_fn=COST_FN, cost_fp=COST_FP)\n",
    "\n",
    "# 3) Target recall (example: 0.70)\n",
    "target_recall = 0.70\n",
    "candidates = sweep.loc[sweep[\"recall\"] >= target_recall]\n",
    "thr_target_recall = float(candidates[\"threshold\"].min()) if len(candidates) else best_f1_thr\n",
    "\n",
    "print(f\"\\nChosen thresholds:\")\n",
    "print(f\"- Best-F1 on VAL: {best_f1_thr:.6f} (F1={best_f1_row['f1']:.4f}, P={best_f1_row['precision']:.4f}, R={best_f1_row['recall']:.4f})\")\n",
    "print(f\"- Cost-min on VAL: {cost_thr:.6f} (min cost={min_cost:.2f}, FN cost={COST_FN}, FP cost={COST_FP})\")\n",
    "print(f\"- Target recall≥{target_recall:.2f}: {thr_target_recall:.6f}\")\n",
    "\n",
    "# Evaluate these thresholds on TEST\n",
    "metrics_best_f1   = evaluate_at(y_test, y_test_probs, best_f1_thr,   \"TEST Best-F1\")\n",
    "metrics_cost_opt  = evaluate_at(y_test, y_test_probs, cost_thr,      \"TEST Cost-Optimal\")\n",
    "metrics_recall_t  = evaluate_at(y_test, y_test_probs, thr_target_recall, \"TEST Target-Recall\")\n",
    "\n",
    "# Save artifacts\n",
    "sweep.to_csv(os.path.join(ARTIFACTS_DIR, \"threshold_sweep_val.csv\"), index=False)\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"chosen_thresholds.json\"), \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_f1_thr\": best_f1_thr,\n",
    "        \"cost_thr\": cost_thr,\n",
    "        \"target_recall_thr\": thr_target_recall,\n",
    "        \"val_pr_auc\": val_pr,\n",
    "        \"test_pr_auc\": test_pr\n",
    "    }, f, indent=2)\n",
    "\n",
    "# =========================\n",
    "# Optional: XGBoost baseline + simple ensemble\n",
    "# =========================\n",
    "if HAVE_XGB:\n",
    "    print(\"\\nTraining XGBoost baseline on last-timestep features...\")\n",
    "    # Use last timestep features for tabular model\n",
    "    X_train_tab = X_train_res[:, -1, :]\n",
    "    X_val_tab   = X_val[:, -1, :]\n",
    "    X_test_tab  = X_test[:, -1, :]\n",
    "\n",
    "    # scale_pos_weight = (neg/pos)\n",
    "    n_pos = max(1, int(np.sum(y_train_res == 1)))\n",
    "    n_neg = max(1, int(np.sum(y_train_res == 0)))\n",
    "    spw = n_neg / n_pos\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        eval_metric=\"aucpr\",\n",
    "        scale_pos_weight=spw,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    xgb.fit(\n",
    "        X_train_tab, y_train_res,\n",
    "        eval_set=[(X_val_tab, y_val)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    y_test_xgb = xgb.predict_proba(X_test_tab)[:, 1]\n",
    "\n",
    "    # Simple average ensemble\n",
    "    y_test_ens = 0.5 * y_test_probs + 0.5 * y_test_xgb\n",
    "    ens_pr = average_precision_score(y_test, y_test_ens)\n",
    "    ens_roc = roc_auc_score(y_test, y_test_ens)\n",
    "    print(f\"\\nXGB TEST PR AUC:  {average_precision_score(y_test, y_test_xgb):.4f} | ROC AUC: {roc_auc_score(y_test, y_test_xgb):.4f}\")\n",
    "    print(f\"ENS TEST PR AUC:  {ens_pr:.4f} | ROC AUC: {ens_roc:.4f}\")\n",
    "\n",
    "    # Evaluate ensemble at cost-min threshold tuned on VAL (re-tune on VAL for fair comparison if you like)\n",
    "    # For quick demo, reuse LSTM VAL thresholds on ensemble:\n",
    "    evaluate_at(y_test, y_test_ens, best_f1_thr, \"TEST Ensemble @Best-F1(thr from LSTM)\")\n",
    "    evaluate_at(y_test, y_test_ens, cost_thr,    \"TEST Ensemble @Cost-Optimal(thr from LSTM)\")\n",
    "\n",
    "# =========================\n",
    "# Save model\n",
    "# =========================\n",
    "model.save(MODEL_OUT)\n",
    "print(f\"\\nSaved LSTM to {MODEL_OUT}\")\n",
    "print(f\"Artifacts in: {ARTIFACTS_DIR}/ (threshold_sweep_val.csv, chosen_thresholds.json, best_lstm.keras)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c46d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893/893 [==============================] - 5s 5ms/step\n",
      "ROC AUC: 0.8336\n",
      "PR  AUC: 0.1548\n",
      "\n",
      "Top thresholds by F1:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.183908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.134454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.109290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.099099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.086275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.042471</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.076125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.037801</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.068536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.033233</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.060942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold  precision    recall        f1\n",
       "98       0.99   0.280000  0.233333  0.254545\n",
       "97       0.98   0.140351  0.266667  0.183908\n",
       "96       0.97   0.089888  0.266667  0.134454\n",
       "95       0.96   0.075000  0.300000  0.120000\n",
       "94       0.95   0.065359  0.333333  0.109290\n",
       "93       0.94   0.057292  0.366667  0.099099\n",
       "92       0.93   0.048889  0.366667  0.086275\n",
       "91       0.92   0.042471  0.366667  0.076125\n",
       "90       0.91   0.037801  0.366667  0.068536\n",
       "89       0.90   0.033233  0.366667  0.060942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best F1 threshold: 0.9900 (F1=0.2545, Precision=0.2800, Recall=0.2333)\n",
      "Threshold for recall ≥ 0.70: 0.0010\n",
      "\n",
      "=== Best-F1 choice (threshold=0.9900) ===\n",
      "Confusion Matrix:\n",
      "[[28524    18]\n",
      " [   23     7]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9992    0.9994    0.9993     28542\n",
      "         1.0     0.2800    0.2333    0.2545        30\n",
      "\n",
      "    accuracy                         0.9986     28572\n",
      "   macro avg     0.6396    0.6164    0.6269     28572\n",
      "weighted avg     0.9984    0.9986    0.9985     28572\n",
      "\n",
      "\n",
      "=== Target-recall choice (threshold=0.0010) ===\n",
      "Confusion Matrix:\n",
      "[[    0 28542]\n",
      " [    0    30]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.0000    0.0000    0.0000     28542\n",
      "         1.0     0.0010    1.0000    0.0021        30\n",
      "\n",
      "    accuracy                         0.0010     28572\n",
      "   macro avg     0.0005    0.5000    0.0010     28572\n",
      "weighted avg     0.0000    0.0010    0.0000     28572\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hisham/micromamba/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hisham/micromamba/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/hisham/micromamba/envs/myenv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# 1) Predict probabilities on the test set\n",
    "y_pred_probs = model.predict(X_test).ravel()\n",
    "\n",
    "# 2) Global, threshold-independent metrics\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "pr_auc  = average_precision_score(y_test, y_pred_probs)  # area under PR curve\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR  AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# 3) Threshold sweep\n",
    "#    Adjust the range/resolution if you like; include a very low threshold for extreme recall\n",
    "thresholds = np.unique(np.concatenate([\n",
    "    np.linspace(0.001, 0.5, 50),\n",
    "    np.linspace(0.5, 0.99, 50)\n",
    "]))\n",
    "\n",
    "rows = []\n",
    "for thr in thresholds:\n",
    "    y_pred = (y_pred_probs > thr).astype(int)\n",
    "    p = precision_score(y_test, y_pred, zero_division=0)\n",
    "    r = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    rows.append((thr, p, r, f1))\n",
    "\n",
    "sweep = pd.DataFrame(rows, columns=[\"threshold\", \"precision\", \"recall\", \"f1\"]).sort_values(\"threshold\").reset_index(drop=True)\n",
    "\n",
    "# Show the top few thresholds by F1 (helps you pick a good trade-off)\n",
    "print(\"\\nTop thresholds by F1:\")\n",
    "display(sweep.sort_values(\"f1\", ascending=False).head(10))\n",
    "\n",
    "# 4) Choose thresholds:\n",
    "#    (a) Best F1\n",
    "best_f1_row = sweep.loc[sweep[\"f1\"].idxmax()]\n",
    "best_f1_thr = float(best_f1_row[\"threshold\"])\n",
    "print(f\"\\nBest F1 threshold: {best_f1_thr:.4f} (F1={best_f1_row['f1']:.4f}, \"\n",
    "      f\"Precision={best_f1_row['precision']:.4f}, Recall={best_f1_row['recall']:.4f})\")\n",
    "\n",
    "#    (b) Threshold to reach a target recall (e.g., 0.70). Adjust as needed.\n",
    "target_recall = 0.70\n",
    "cand = sweep.loc[sweep[\"recall\"] >= target_recall]\n",
    "if len(cand):\n",
    "    thr_target_recall = float(cand.sort_values(\"threshold\").iloc[0][\"threshold\"])\n",
    "    print(f\"Threshold for recall ≥ {target_recall:.2f}: {thr_target_recall:.4f}\")\n",
    "else:\n",
    "    thr_target_recall = best_f1_thr\n",
    "    print(f\"No threshold reached recall ≥ {target_recall:.2f}. Falling back to best-F1 threshold {best_f1_thr:.4f}\")\n",
    "\n",
    "# 5) Evaluate at chosen thresholds\n",
    "def eval_at(thr, name):\n",
    "    yp = (y_pred_probs > thr).astype(int)\n",
    "    print(f\"\\n=== {name} (threshold={thr:.4f}) ===\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, yp))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, yp, digits=4))\n",
    "\n",
    "eval_at(best_f1_thr, \"Best-F1 choice\")\n",
    "eval_at(thr_target_recall, \"Target-recall choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9081c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
