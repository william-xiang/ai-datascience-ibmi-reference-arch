{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ca6c8e",
   "metadata": {},
   "source": [
    "A simple server program will deploy the trained model, using the Flask API. Once the server is running, requests can be sent to the server using the HTTP POST method. These requests can be sent as raw data, which will then be preprocessed by this program to be then fed into the inference model.\n",
    "\n",
    "Note: Here the Autoencoder model architecture must mirror the saved model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422284fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# scaler and label loading\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "label_encoders = joblib.load(\"label_encoders.pkl\")\n",
    "\n",
    "class Autoencoder(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 8),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(8, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(32, input_size),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Loading the trained model\n",
    "model = Autoencoder(input_size=41)\n",
    "model.load_state_dict(torch.load(\"autoencoder.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Threshold from training\n",
    "THRESHOLD = 0.107242\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    features = data.get(\"features\")\n",
    "\n",
    "    if not features or len(features) != 41:\n",
    "        return jsonify({\"error\": \"Must provide 41 raw features\"}), 400\n",
    "\n",
    "    # Convert input to DataFrame\n",
    "    input_df = pd.DataFrame([features], columns=[f\"feature_{i}\" for i in range(41)])\n",
    "\n",
    "    # Apply saved label encoders\n",
    "    for col in ['feature_1', 'feature_2', 'feature_3']:\n",
    "        le = label_encoders.get(col)\n",
    "        if le:\n",
    "            try:\n",
    "                input_df[col] = le.transform(input_df[col])\n",
    "            except ValueError as e:\n",
    "                return jsonify({\"error\": f\"Invalid value for {col}: {e}\"}), 400\n",
    "        else:\n",
    "            return jsonify({\"error\": f\"Missing label encoder for {col}\"}), 500\n",
    "\n",
    "    # Scale using saved scaler\n",
    "    try:\n",
    "        X_scaled = scaler.transform(input_df.values)\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Scaling failed: {str(e)}\"}), 500\n",
    "\n",
    "    # Predict reconstruction error\n",
    "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(X_tensor)\n",
    "        error = torch.mean((X_tensor - reconstructed) ** 2).item()\n",
    "\n",
    "    is_anomaly = error > THRESHOLD\n",
    "\n",
    "    return jsonify({\n",
    "        \"reconstruction_error\": error,\n",
    "        \"anomaly\": is_anomaly\n",
    "    })\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4ce47",
   "metadata": {},
   "source": [
    "A sample request program is provided here. This program can be used to make standalone requests to the inference model, or be automated to run as a batch processor, reading from access logs or audit journal entries. Alternatively, a real-time setup can be created where entries are made to a log through the IBM i audit journal, which will then trigger an event handler such as Manzan that will send the log entry to the inference model, and then take appropriate actions in case an anomaly is detected; thus encapsulating a real-time protection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e368f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Raw data, seperated by commas and sent as a string\n",
    "raw_data = \"0,tcp,private,REJ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,117,10,0.00,0.00,1.00,1.00,0.09,0.06,0.00,255,10,0.04,0.05,0.00,0.00,0.00,0.00,1.00,1.00,neptune,21\"\n",
    "\n",
    "# String split to retrieve features\n",
    "fields = raw_data.strip().split(',')\n",
    "\n",
    "# Remove label and difficulty columns\n",
    "features = fields[:-2]  # drop 'normal' and '21'\n",
    "\n",
    "processed_features = []\n",
    "for i, val in enumerate(features):\n",
    "    # Keep strings for categorical features\n",
    "    if i in [1, 2, 3]:  # feature_1, feature_2, feature_3 are categorical\n",
    "        processed_features.append(val)\n",
    "    else:\n",
    "        processed_features.append(float(val))\n",
    "\n",
    "# Prepare JSON payload\n",
    "payload = {\n",
    "    \"features\": processed_features\n",
    "}\n",
    "\n",
    "# Server request\n",
    "response = requests.post(\"http://localhost:8000/predict\", json=payload)\n",
    "\n",
    "# Retrieve results from the response, which indicate whether the login string is normal or an anomaly\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ Server Response:\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(\"❌ Error:\")\n",
    "    print(response.status_code, response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
